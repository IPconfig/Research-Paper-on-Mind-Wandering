\newgeometry{hmargin=1.4cm,vmargin=1.0cm,landscape}
\onecolumn % use the full width of the page
% header and footer information
\topcaption{Detection methods for mind wandering} \label{tab:data}
\tablefirsthead{\toprule}
% the contents of each repeating tabular head. 
\tablehead{\multicolumn{2}{l}{Table \ref{tab:data}}{continued from previous page}\\
        \toprule
        Reference & Task & Modalities used & Sensors Used & Features Extracted \footnotemark[1] & Reporting MW \footnotemark[2] & ML algorithm(s) & Performance & Notes\\
        \midrule}
% Tabular head of last page of the table 
\tablelasthead{\multicolumn{2}{l}{Table \ref{tab:data}} concluded from previous page\\
        \toprule
        Reference & Task & Modalities used & Sensors Used & Features Extracted \footnotemark[1] & Reporting MW \footnotemark[2] & ML algorithm(s) & Performance & Notes\\
        \midrule}
\tabletail{\hline\multicolumn{9}{r}{{Continued on next page}} \\ \bottomrule}

% Start of Table
\begin{ThreePartTable}
\small % change font size to small. If not used change column size performance  24 -> 27mm and notes 46 -> 43
        \begin{xtabular}{P{20mm}P{24mm}P{22mm}P{24mm}P{28mm}P{21mm}P{26mm}P{24mm}P{42mm}}
                \toprule
                Reference & Task & Modalities used & Sensors Used & Features Extracted \footnotemark[1] & Reporting MW \footnotemark[2] & ML algorithm(s) & Performance & Notes\\
                \midrule
                Bixler et al. (2015) \cite{Bixler2015AutomaticPhysiology} & Reading & Eye gaze, physiology, context & Eye tracker, wrist sensor for physiology & GGF (46), LGF (23), SC (43), ST (43), CF (11) & WP, EP (both auditory) & 13 supervised ML classifiers & Kappa of 0.19 & Larger gaze window size results in a higher Accuracy \\ \midrule
                Bixler et al. (2015) \cite{Bixler2015AutomaticAwareness} & Reading & Eye gaze & Eye tracker & GGF (46), LGF (20) & Pseudo-random AP, SCR & 10 ML classifiers & Kappa of 0.45, Accuracy of 74\% & Context features did not improve classification, SVM classifier works best, larger window sizes improved accuracy\\ \midrule
                Bixler et al. (2014) \cite{Bixler2014TowardWanderingd} & Reading & Eye gaze, context & Eye tracker & GGF (30), LGF (19), CF(11) & WP, EP (both auditory) & 20 supervised ML classifiers & Kappa of 0.28, Accuracy of 72\% (end-of-page), Kappa of 0.17, Accuracy of 59\% (within-page) & Bayes net and naïve bayes classifiers worked best \\ \midrule
                Bixler et al. (2016) \cite{Bixler2016AutomaticReadingd} & Reading & Eye gaze, context & Eye tracker & GGF (46), LGF (23), CF (11) & WP, EP (both auditory) & 20 supervised ML classifiers & Kappa of 0.31, Accuracy of 72\% (end-of-page), Kappa of 0.18, Accuracy of 67\% (within-page) & Bayes net and naïve bayes classifiers worked best, window size had no effect \\ \midrule
                Blanchard et al. (2014) \cite{Blanchard2014AutomatedLearning} & Reading & Physiology, context & Wrist sensor for physiology & SC (43), ST (43), CF (11) & WP, EP (both auditory) & Unspecified amount of supervised classifiers & Kappa of 0.22 (within-page), Kappa of 0.14 (end-of-page) & LADTree classifier performed best \\ \midrule
                Gwizdka (2019) \cite{Gwizdka2019ExploringTasks} & Reading & Eye gaze & Eye tracker & 27 eye gaze features & Pseudo-random WP (visual) & ML classifiers & Accuracy of 89\% & Random forest classifier performed best, Accuracy might not be reliable due to resampling, window size had very little effect \\ \midrule
                Jo et al. (2017) \cite{Jo2017AMind} & Watching a video & Words in video & N/A & High frequency words & Not watching is compared with watching & N/A & N/A & Provides initial evidence that MW can be detected using high frequency words in video lectures\\ \midrule
                Stewart et al. (2016) \cite{Stewart2016WheresViewing} & Watching a video & Facial features and body movement & Webcam & Facial features (75), body movement features (3) & SCR & Several ML classifiers & F$_1$ score of 0.30 & SVM classifier works best\\ \midrule
                Stewart et al. (2017) \cite{Stewart2017FaceComprehension} & Watching a video & Facial features and body movement & Webcam & Facial features (75), body movement features (3) & SCR & 9 supervised classification techniques & F$_1$ score of 0.39 & Larger window sizes performed slightly better, SVM classifier works best\\ \midrule
                Zhao et al. (2017) \cite{Zhao2017ScalableApproach} & Watching a video & Eye gaze & Webcam & GGF and LGF (58 in total) & SCR & Logistic Regression, Linear SVM, Naive Bayes & F$_1$ score of 0.40 & Naive Bayes net works best\\ \midrule
                Zhang et al. (2016) \cite{ISI:000443429900018} & Watching a video & Eye gaze, pupillometry & Camera of mobile device & Eye movement, pupil index & Participants review images afterwards & Logistic regression, Linear SVM, HMM & Accuracy of 53\% & Linear SVM classifier works best, largest window size did not result in highest accuracy\\ \midrule
                Pham et al. (2015) \cite{Pham2015Attentivelearner:Tracking} & Watching a video & Fingertip transparency, context & Mobile phone cameras & Heart rate features (12) and CF (7) & AP & Supervised ML classifiers & Kappa of 0.22, Accuracy of 71\% & KNN classifier (K = 5) performed best\\ \midrule
                Hutt et al. (2017) \cite{Hutt2017OutClassroom} & Interacting with learning technology & Eye gaze, context & Eye tracker & GGF (57), LGF (81), CF (8) & Pseudo-random AP & Bayesian Networks & F$_1$ score of 0.59 & -\\ \midrule
                Cheetham et al. (2016) \cite{Cheetham2016AutomatedApplication} & Eyes-closed FA meditation & Biosignals & Biosensors & Respiration, heart rate, electrocardiogram, electromyogram, electrodermal acitivity & SCR & N/A & Accuracy of 85\% & Performance achieved for area under the receiver operator characteristic curve\\ \midrule
                Da Silva et al. (2018) \cite{DaSilva2018WanderingWandering} & Maintain access to memory items (letters) while completing math equations & Mouse movements & Computer mouse & Time to press start, initiation time, total distance, average speed, speed errors & Probes after each set & N/A & N/A & Provides initial evidence that mouse tracking can be used to predict MW\\ \midrule
                Gontier (2016) \cite{Gontier2016HowEnvironment} & Various extra-vehicular activities at the Mars Desert Research Station & Heart rate & ECG sensor & Measures of heart rate variability & AP & N/A & N/A & This study was only done with 1 participant, so did not mention much in terms of relevant results \\ \midrule
                Mishchenko et al. (2015) \cite{Mishchenko2015DetectingTespiti} & Controlling a passenger train in a train simulator program & Electroence\-phalo\-graphic brain activity & Modified EPOC EEG device & Feature vector containing 252 EEG spectral power values & AP & Several SVM classifiers & Accuracy of 90\% & Accuracy is cross-validation accuracy \\ \midrule
                Russell et al. (2016) \cite{Russell2016MonitoringEnvironments} & Watching flickers on a computer screen & Electroence\-phalo\-graphic brain activity & Electroence\-phalo\-gram & ssVEP powers & N/A & N/A & N/A & An indication that high frequency ssVEPs are attention sensitive is given, due to unexpected results further research is needed\\ \midrule
                \bottomrule
        \end{xtabular}
        % Add Footnotes
        \begin{tablenotes}
                \small
                \item[1] \emph{Features extracted:} GGF = global gaze features, LGF = local gaze features, SC = skin conductance, ST = skin temperature, CF = context features
                \item[2] \emph{Reporting MW:} WP = Within-page probes, EP = End-of-page probes, AP = Auditory probes, SCR = self-caught reports
        \end{tablenotes}
\end{ThreePartTable}
\restoregeometry % restore normal page margins
\twocolumn       % set document to two columns again