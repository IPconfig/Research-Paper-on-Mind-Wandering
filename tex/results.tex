Data extracted from a total of 18 studies are represented in table \ref{tab:data}
The table includes the following data for each of the studies:
\begin{itemize}
    \item Reference to the study
    \item The task requested to perform
    \item The modalities used to measure mind wandering
    \item Features extracted
    \item Equipment used
    \item How Mind Wandering is reported
    \item Which Machine Learning models are used
    \item The performance
    \item If the dataset has been published
    \item Additional Notes
\end{itemize}

\lipsum[5]
\newpage
\onecolumn

\begin{sidewaystable} % Landscape page
\begin{table}[H]
\centering
\caption{Extracted data}
\label{tab:data}
\begin{threeparttable}
\begin{tabulary}{\textheight}{LLLLLLLLLL}
\toprule
Reference & Task & Modalities used & Features extracted & Equipment used & Reporting MW & ML model(s) & Performance & Published dataset (y/n) & Notes \\
		\midrule
\cite{Bixler2015AutomaticPhysiology}   &  Reading 	& Eye gaze, physiology, contextual cues & GGF (46), LGF(23), SC (43), ST (43), CF (11)  & Eye tracker   & WP, EP  &  Thirteen supervised ML algorithms from Weka        & Kappa of 0.19 & n & -\\
\cite{Bixler2015AutomaticAwareness}     &  Reading  & Eye gaze                              & GGF (46), LGF (20)                            & Eye tracker   & Pseudo-random AP, SCR  &  Ten classifiers implemented in Weka & Kappa of 0.45 & n & Context features were tested, but did not improve classification\\
\cite{Bixler2016AutomaticReading}       &  Reading 	& Eye gaze, contextual cues             & GGF (46), LGF (23), CF (11)                   & Eye tracker   & WP, EP & Twenty supervised ML algorithms from Weka            & Kappa of 0.31 & n & Bayes Net was best classifier\\
\cite{Bixler2014TowardWandering}        &  Reading  & Eye gaze, contextual cues             & GGF (30), LGF (19), CF (12)                   & Eye tracker   & WP, EP & Twenty supervised ML algorithms from Weka            & Kappa of 0.28 for end-of-page, kappa of 0.17 for within-page & n & -\\      
\cite{Blanchard2014AutomatedLearning}   &  Reading	& Physiology                                                                                            & SC (43), ST (43), CF (11)                                                          & Wearable sensor & WP, EP                                     & Supervised ML algorithms from Weka & kappa of 0.22 & n & -\\
\cite{Cheetham2016AutomatedApplication} &  Eyes-closed FA meditation  	& Respiration, heart rate, electrocardiogram, electromyogram, electrodermal activity & N/S                                                                               & Biosensors  &  SCR                                           & N/S & Accuracy of 85\% (area under the receiver operator characteristic curve) & n & -\\
\cite{DaSilva2018WanderingWandering}   &  Maintain access to memory items (letters) while completing math equitions & Mouse movements                      & Timte to press start, initiation time, total distance, average speed, speed errors & Regular computer & Probes after each set                     & Mixed effects logistic regression & N/S & n & Provides initial evidence that mouse tracking can be used to predict MW\\
\cite{Gontier2016HowEnvironment}        &  Various extra-vehicular activities at the Mars Desert Research Station  		& Heart rate                        & Measures of heart rate variability                                                 & ECG sensor  &  AP                                            & - & - & n & -\\
\cite{Gwizdka2019ExploringTasks}        &  Reading    		& Eye gaze                                                                                      & Twenty-seven variables related to eye gaze                                         & Eye tracker & PSeudo-randomly selected probes                & Classification are run using Weka 3.8 & Accuracy of 73-89\% & n & Accuracy might not be reliable because of resampling\\
\cite{Hutt2017OutClassroom}            &  Interacting with learning technology  		& Eye gaze                                                          & GGF (57, LGF (81), CF (8)                                                          & Eye tracker (commercial off the shelf) & Pseudo-random AP    & Bayesian Networks in Weka & Total accuracy of 57\% & n & -\\
\cite{Jo2017AMind}                      & Watching a video lecture & Words in video & High frequency words & N/A & Not watching a video is compared with watching & N/A & N/a & n & Provides initial evidence that MW can be detected using high frequency words in video lectures\\
\cite{Mishchenko2015DetectingTespiti}   & Controlling a passenger train using the computer simulator program "Microsoft Train Simulator" & Electroencephalographic brain activity & Feature vector containing 252 EEG spectral power values & Modified EPOC EEG device & AP & A system consisting of several SVM classifiers & Accuracy of 90\% when the model was trained & n & -\\
\cite{Pham2015Attentivelearner:Tracking} & Watching a video lecture & Heart rate and fingertip transparency & Heart rate features (12) and CF (7) & Tangible video control channel, an implicit heart rate sensing module, an on-screen AttentiveWidget visualizing real-time states of video control and heart rate sensing & AP & Supervised ML algorithms from Weka & kappa of 0.22 & n & -\\
\cite{Russell2016MonitoringEnvironments} & Watching flickers on a computer screen & Electroencephalographic brain activity & ssVEP powers & Electroencephalogram & N/A & N/A & N/S & n & An indication that high frequency ssVEPs are attention sensitive is given, due to unexpected results further research is needed\\
\cite{Stewart2017FaceComprehension}     & Watching a film on a computer screen & Facial features and body movement & Facial features (75), body movement features (3) & Webcam, FACET vision software & SCR & Supervised classification techniques & F1 score of 0.39 & n & -\\
\cite{Stewart2016WheresViewing}         & Watching a film on a computer screen & Facial features and body movement & Facial features (75), body movement features (3) & Webcam, FACET vision software & SCR & Supervised classification techniques & SVM classifier, F1 score of 0.30 & n & SVM classifier works best\\
\cite{ISI:000443429900018}              & Watching a teaching video on a mobile device & Eye gaze, pupillometry & Eye movement, pupil index & Camera of mobile device & Participants review imaged afterwards & Logistic regression, SVM, HMM & Accuracy of 53\% & n & SVM classifier works best\\
\cite{Zhao2017ScalableApproach}         & Watching a video on a computer screen & Eye gaze & GGF, LGF, 58 in total & Low-end webcams & SCR & Logistic Regression, Linear SVM, Naive Bayes & F1 score of 0.40 & n & Naive Bayes net works best\\
\bottomrule
\end{tabulary}
\begin{tablenotes}\footnotesize
    \note This is a long explanation going over multiple lines. This is a long explanation going over multiple lines. This is a long explanation going over multiple lines. This is a long explanation going over multiple lines. This is a long explanation going over multiple lines.
\end{tablenotes}
\end{threeparttable}
\end{table}
\end{sidewaystable}
\twocolumn

\subsection{Tasks Evaluated}

\subsection{Features Used}

\subsection{Measuring Mind Wandering}

\subsection{Equipment Used}
\lipsum