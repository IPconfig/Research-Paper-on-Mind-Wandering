The studies shown in Table \ref{tab:data} show a variety of different tasks that the participants of the study had to perform, each with different advantages related to that study. The two most used tasks were reading text and watching some type of content on a computer screen. These two methods are probably the most popular because they are easy to distribute to a large audience and do not require any advanced equipment. Other than these two tasks, none of them occurred more than once, because the others were usually specific to a certain study, such as interacting with GuruTutor \cite{Hutt2017OutClassroom}. An interesting thing to note here is that the type of performed tasks did not seem to correlate with the modalities that were used. This can be seen in Table \ref{tab:data}, the task of watching something on a computer screen was evaluated in studies that recorded the modalities of eye gaze \cite{Zhao2017ScalableApproach}, EEG brain activity \cite{Russell2016MonitoringEnvironments}, facial features \cite{Stewart2017FaceComprehension} and heart rate \cite{Pham2015Attentivelearner:Tracking}. This suggests that automated detection of MW can be detected in a wide variety of ways in the same context, thus making the technology very flexible in terms of implementation.